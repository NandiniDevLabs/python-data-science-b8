
Machine Learning 
Supervised -- Regression (Continuous) and Classification (discrete or categories)
Unsupervised -- 

Linear Regression --> OLS  or Gradient Descent
Simple Linear Regression
Multiple Linear Regression

Polynomial Regression
Feature Scaling -- 

Bias-Variance Trade Off  -- Underfitting and Overfitting

Cross-Validation --> Train, Validation and Test  Set --> 3 data sets

Regularization - L1 and L2, and Elastic Net 
Ridge (L2) Regression
Lasso (L1) Regression
Elastic Net Regression --> L1 + L2




Classification --  KNN, SVM
Tree Based -- Decision Tree, 
Random Forest, Bagging and Boosting

Unsupervised -- Clustering (KMeans, Density, ), Anomaly Detection, PCA -> 3hrs



SVM --> 

SVC - 
Hyperplane --> Point, Line, Plane, Hyperplane
Maximum Margin --> 
Support Vectors --> Soft margin --> Allow mis-classification --> C (Regularization parameter) --> To avoid Overfitting
Kernels --> Polynomial or RBF


SVR -
Hyperplane -->  Point, Line, Plane, Hyperplane
Margin of tolernace --> Epsilon 
Support Vectors --> C (Regularization parameter) --> To avoid Overfitting
Loss function --> 
Epsilon Insensitive Tube 



-------------------------
Overview of Supervised Machine Learning
-------------------------
Supervised Machine Learning --> You know 'Y'

Based on type of data of 'Y'
If Y is continuous --> Regression Problem
If Y is categorical --> Classification Problem


1. Linear Regression 
2. Polynomial Regression
3. Regularization - L1(Lasso), L2(Ridge), Elastic
4. Classification - KNN 
5. SVM - SVC, SVR 
6. Decision Tree Classifier and Decision Tree Regressor
7. Random Forest Classifier and Random Forest Regressor


Unsupervised ML
Clustering - KMeans, Hierarchical, DBSCAN ->
PCA
Anomaly Detection 




